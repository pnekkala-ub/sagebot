{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: rouge_score in /Users/madhavappaneni/Library/Python/3.9/lib/python/site-packages (0.1.2)\n",
      "Requirement already satisfied: nltk in /Users/madhavappaneni/Library/Python/3.9/lib/python/site-packages (3.8.1)\n",
      "Requirement already satisfied: absl-py in /Users/madhavappaneni/Library/Python/3.9/lib/python/site-packages (1.4.0)\n",
      "Requirement already satisfied: transformers in /Users/madhavappaneni/Library/Python/3.9/lib/python/site-packages (4.26.1)\n",
      "Requirement already satisfied: evaluate in /Users/madhavappaneni/Library/Python/3.9/lib/python/site-packages (0.4.0)\n",
      "Requirement already satisfied: sentencepiece in /Users/madhavappaneni/Library/Python/3.9/lib/python/site-packages (0.1.97)\n",
      "Requirement already satisfied: numpy in /Users/madhavappaneni/Library/Python/3.9/lib/python/site-packages (from rouge_score) (1.24.1)\n",
      "Requirement already satisfied: six>=1.14.0 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from rouge_score) (1.15.0)\n",
      "Requirement already satisfied: tqdm in /Users/madhavappaneni/Library/Python/3.9/lib/python/site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/madhavappaneni/Library/Python/3.9/lib/python/site-packages (from nltk) (2022.10.31)\n",
      "Requirement already satisfied: click in /Users/madhavappaneni/Library/Python/3.9/lib/python/site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: joblib in /Users/madhavappaneni/Library/Python/3.9/lib/python/site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: filelock in /Users/madhavappaneni/Library/Python/3.9/lib/python/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /Users/madhavappaneni/Library/Python/3.9/lib/python/site-packages (from transformers) (0.13.1)\n",
      "Requirement already satisfied: requests in /Users/madhavappaneni/Library/Python/3.9/lib/python/site-packages (from transformers) (2.28.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/madhavappaneni/Library/Python/3.9/lib/python/site-packages (from transformers) (22.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/madhavappaneni/Library/Python/3.9/lib/python/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/madhavappaneni/Library/Python/3.9/lib/python/site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: pandas in /Users/madhavappaneni/Library/Python/3.9/lib/python/site-packages (from evaluate) (1.5.3)\n",
      "Requirement already satisfied: xxhash in /Users/madhavappaneni/Library/Python/3.9/lib/python/site-packages (from evaluate) (3.2.0)\n",
      "Requirement already satisfied: multiprocess in /Users/madhavappaneni/Library/Python/3.9/lib/python/site-packages (from evaluate) (0.70.14)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /Users/madhavappaneni/Library/Python/3.9/lib/python/site-packages (from evaluate) (2.10.1)\n",
      "Requirement already satisfied: responses<0.19 in /Users/madhavappaneni/Library/Python/3.9/lib/python/site-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: dill in /Users/madhavappaneni/Library/Python/3.9/lib/python/site-packages (from evaluate) (0.3.6)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /Users/madhavappaneni/Library/Python/3.9/lib/python/site-packages (from evaluate) (2023.3.0)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /Users/madhavappaneni/Library/Python/3.9/lib/python/site-packages (from datasets>=2.0.0->evaluate) (11.0.0)\n",
      "Requirement already satisfied: aiohttp in /Users/madhavappaneni/Library/Python/3.9/lib/python/site-packages (from datasets>=2.0.0->evaluate) (3.8.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/madhavappaneni/Library/Python/3.9/lib/python/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/madhavappaneni/Library/Python/3.9/lib/python/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (3.0.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/madhavappaneni/Library/Python/3.9/lib/python/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/madhavappaneni/Library/Python/3.9/lib/python/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (22.1.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/madhavappaneni/Library/Python/3.9/lib/python/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/madhavappaneni/Library/Python/3.9/lib/python/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/madhavappaneni/Library/Python/3.9/lib/python/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.8.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/madhavappaneni/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/madhavappaneni/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/madhavappaneni/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/madhavappaneni/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/madhavappaneni/Library/Python/3.9/lib/python/site-packages (from pandas->evaluate) (2022.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/madhavappaneni/Library/Python/3.9/lib/python/site-packages (from pandas->evaluate) (2.8.2)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement bleurt (from versions: none)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for bleurt\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install rouge_score nltk absl-py transformers evaluate sentencepiece\n",
    "!pip3 install bleurt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import torch\n",
    "import evaluate\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Can't load the configuration of './madhavappaneni/CC-BERT2BERT/'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure './madhavappaneni/CC-BERT2BERT/' is the correct path to a directory containing a config.json file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/configuration_utils.py:620\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    619\u001b[0m     \u001b[39m# Load from local folder or from cache or download from model Hub and cache\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m     resolved_config_file \u001b[39m=\u001b[39m cached_file(\n\u001b[1;32m    621\u001b[0m         pretrained_model_name_or_path,\n\u001b[1;32m    622\u001b[0m         configuration_file,\n\u001b[1;32m    623\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m    624\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m    625\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    626\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m    627\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m    628\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[1;32m    629\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m    630\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m    631\u001b[0m         subfolder\u001b[39m=\u001b[39;49msubfolder,\n\u001b[1;32m    632\u001b[0m         _commit_hash\u001b[39m=\u001b[39;49mcommit_hash,\n\u001b[1;32m    633\u001b[0m     )\n\u001b[1;32m    634\u001b[0m     commit_hash \u001b[39m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/utils/hub.py:409\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    408\u001b[0m     \u001b[39m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 409\u001b[0m     resolved_file \u001b[39m=\u001b[39m hf_hub_download(\n\u001b[1;32m    410\u001b[0m         path_or_repo_id,\n\u001b[1;32m    411\u001b[0m         filename,\n\u001b[1;32m    412\u001b[0m         subfolder\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m \u001b[39mif\u001b[39;49;00m \u001b[39mlen\u001b[39;49m(subfolder) \u001b[39m==\u001b[39;49m \u001b[39m0\u001b[39;49m \u001b[39melse\u001b[39;49;00m subfolder,\n\u001b[1;32m    413\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m    414\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m    415\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m    416\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m    417\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    418\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m    419\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[1;32m    420\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m    421\u001b[0m     )\n\u001b[1;32m    423\u001b[0m \u001b[39mexcept\u001b[39;00m RepositoryNotFoundError:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/huggingface_hub/utils/_validators.py:112\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39mif\u001b[39;00m arg_name \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mrepo_id\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mfrom_id\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mto_id\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m--> 112\u001b[0m     validate_repo_id(arg_value)\n\u001b[1;32m    114\u001b[0m \u001b[39melif\u001b[39;00m arg_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtoken\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m arg_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/huggingface_hub/utils/_validators.py:160\u001b[0m, in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[39mif\u001b[39;00m repo_id\u001b[39m.\u001b[39mcount(\u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 160\u001b[0m     \u001b[39mraise\u001b[39;00m HFValidationError(\n\u001b[1;32m    161\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mRepo id must be in the form \u001b[39m\u001b[39m'\u001b[39m\u001b[39mrepo_name\u001b[39m\u001b[39m'\u001b[39m\u001b[39m or \u001b[39m\u001b[39m'\u001b[39m\u001b[39mnamespace/repo_name\u001b[39m\u001b[39m'\u001b[39m\u001b[39m:\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    162\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mrepo_id\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. Use `repo_type` argument if needed.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    163\u001b[0m     )\n\u001b[1;32m    165\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m REPO_ID_REGEX\u001b[39m.\u001b[39mmatch(repo_id):\n",
      "\u001b[0;31mHFValidationError\u001b[0m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': './madhavappaneni/CC-BERT2BERT/'. Use `repo_type` argument if needed.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m model_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m./madhavappaneni/CC-BERT2BERT/\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 8\u001b[0m model \u001b[39m=\u001b[39m EncoderDecoderModel\u001b[39m.\u001b[39;49mfrom_pretrained(\n\u001b[1;32m      9\u001b[0m     model_name, use_auth_token\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mhf_UlIxhPXldjqROtWxDUCmNCBulOqYCfvhmQ\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     10\u001b[0m tokenizer \u001b[39m=\u001b[39m AutoTokenizer\u001b[39m.\u001b[39mfrom_pretrained(\n\u001b[1;32m     11\u001b[0m     model_name, use_auth_token\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhf_UlIxhPXldjqROtWxDUCmNCBulOqYCfvhmQ\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:379\u001b[0m, in \u001b[0;36mEncoderDecoderModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    373\u001b[0m     logger\u001b[39m.\u001b[39mwarning(\n\u001b[1;32m    374\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFast initialization is currently not supported for EncoderDecoderModel. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    375\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFalling back to slow initialization...\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    376\u001b[0m     )\n\u001b[1;32m    377\u001b[0m kwargs[\u001b[39m\"\u001b[39m\u001b[39m_fast_init\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m--> 379\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfrom_pretrained(pretrained_model_name_or_path, \u001b[39m*\u001b[39;49mmodel_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/modeling_utils.py:2079\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2077\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(config, PretrainedConfig):\n\u001b[1;32m   2078\u001b[0m     config_path \u001b[39m=\u001b[39m config \u001b[39mif\u001b[39;00m config \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m pretrained_model_name_or_path\n\u001b[0;32m-> 2079\u001b[0m     config, model_kwargs \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mconfig_class\u001b[39m.\u001b[39;49mfrom_pretrained(\n\u001b[1;32m   2080\u001b[0m         config_path,\n\u001b[1;32m   2081\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m   2082\u001b[0m         return_unused_kwargs\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   2083\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m   2084\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m   2085\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m   2086\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m   2087\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[1;32m   2088\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m   2089\u001b[0m         subfolder\u001b[39m=\u001b[39;49msubfolder,\n\u001b[1;32m   2090\u001b[0m         _from_auto\u001b[39m=\u001b[39;49mfrom_auto_class,\n\u001b[1;32m   2091\u001b[0m         _from_pipeline\u001b[39m=\u001b[39;49mfrom_pipeline,\n\u001b[1;32m   2092\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   2093\u001b[0m     )\n\u001b[1;32m   2094\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2095\u001b[0m     model_kwargs \u001b[39m=\u001b[39m kwargs\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/configuration_utils.py:538\u001b[0m, in \u001b[0;36mPretrainedConfig.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    461\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_pretrained\u001b[39m(\u001b[39mcls\u001b[39m, pretrained_model_name_or_path: Union[\u001b[39mstr\u001b[39m, os\u001b[39m.\u001b[39mPathLike], \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mPretrainedConfig\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    462\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    463\u001b[0m \u001b[39m    Instantiate a [`PretrainedConfig`] (or a derived class) from a pretrained model configuration.\u001b[39;00m\n\u001b[1;32m    464\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[39m    assert unused_kwargs == {\"foo\": False}\u001b[39;00m\n\u001b[1;32m    537\u001b[0m \u001b[39m    ```\"\"\"\u001b[39;00m\n\u001b[0;32m--> 538\u001b[0m     config_dict, kwargs \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mget_config_dict(pretrained_model_name_or_path, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    539\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mmodel_type\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config_dict \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmodel_type\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m config_dict[\u001b[39m\"\u001b[39m\u001b[39mmodel_type\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mmodel_type:\n\u001b[1;32m    540\u001b[0m         logger\u001b[39m.\u001b[39mwarning(\n\u001b[1;32m    541\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mYou are using a model of type \u001b[39m\u001b[39m{\u001b[39;00mconfig_dict[\u001b[39m'\u001b[39m\u001b[39mmodel_type\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m to instantiate a model of type \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    542\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mmodel_type\u001b[39m}\u001b[39;00m\u001b[39m. This is not supported for all configurations of models and can yield errors.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    543\u001b[0m         )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/configuration_utils.py:565\u001b[0m, in \u001b[0;36mPretrainedConfig.get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    563\u001b[0m original_kwargs \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(kwargs)\n\u001b[1;32m    564\u001b[0m \u001b[39m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[0;32m--> 565\u001b[0m config_dict, kwargs \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_get_config_dict(pretrained_model_name_or_path, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    566\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config_dict:\n\u001b[1;32m    567\u001b[0m     original_kwargs[\u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m config_dict[\u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/configuration_utils.py:641\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    638\u001b[0m         \u001b[39mraise\u001b[39;00m\n\u001b[1;32m    639\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    640\u001b[0m         \u001b[39m# For any other exception, we throw a generic error.\u001b[39;00m\n\u001b[0;32m--> 641\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    642\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCan\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt load the configuration of \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mpretrained_model_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. If you were trying to load it\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    643\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m from \u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttps://huggingface.co/models\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, make sure you don\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt have a local directory with the same\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    644\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m name. Otherwise, make sure \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mpretrained_model_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m is the correct path to a directory\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    645\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m containing a \u001b[39m\u001b[39m{\u001b[39;00mconfiguration_file\u001b[39m}\u001b[39;00m\u001b[39m file\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    646\u001b[0m         )\n\u001b[1;32m    648\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    649\u001b[0m     \u001b[39m# Load config dict\u001b[39;00m\n\u001b[1;32m    650\u001b[0m     config_dict \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_dict_from_json_file(resolved_config_file)\n",
      "\u001b[0;31mOSError\u001b[0m: Can't load the configuration of './madhavappaneni/CC-BERT2BERT/'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure './madhavappaneni/CC-BERT2BERT/' is the correct path to a directory containing a config.json file"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, EncoderDecoderModel\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model_name = \"./madhavappaneni/CC-BERT2BERT/\"\n",
    "\n",
    "model = EncoderDecoderModel.from_pretrained(\n",
    "    model_name, use_auth_token=\"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\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name, use_auth_token=\"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\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 10\u001b[0m\n\u001b[1;32m      5\u001b[0m     outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mgenerate(input_ids, max_length\u001b[39m=\u001b[39m\u001b[39m64\u001b[39m,\n\u001b[1;32m      6\u001b[0m                              do_sample\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, num_beams\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n\u001b[1;32m      7\u001b[0m     \u001b[39mreturn\u001b[39;00m (tokenizer\u001b[39m.\u001b[39mdecode(outputs[\u001b[39m0\u001b[39m], skip_special_tokens\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m))\n\u001b[0;32m---> 10\u001b[0m generate_response(\u001b[39m\"\u001b[39;49m\u001b[39mHey! How are you?\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m, in \u001b[0;36mgenerate_response\u001b[0;34m(input_text)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_response\u001b[39m(input_text):\n\u001b[0;32m----> 2\u001b[0m     input_ids \u001b[39m=\u001b[39m tokenizer(\n\u001b[1;32m      3\u001b[0m         input_text, add_special_tokens\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, return_tensors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m     )\u001b[39m.\u001b[39minput_ids\n\u001b[1;32m      5\u001b[0m     outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mgenerate(input_ids, max_length\u001b[39m=\u001b[39m\u001b[39m64\u001b[39m,\n\u001b[1;32m      6\u001b[0m                              do_sample\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, num_beams\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n\u001b[1;32m      7\u001b[0m     \u001b[39mreturn\u001b[39;00m (tokenizer\u001b[39m.\u001b[39mdecode(outputs[\u001b[39m0\u001b[39m], skip_special_tokens\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "def generate_response(input_text):\n",
    "    input_ids = tokenizer(\n",
    "        input_text, add_special_tokens=False, return_tensors=\"pt\"\n",
    "    ).input_ids\n",
    "    outputs = model.generate(input_ids, max_length=64,\n",
    "                             do_sample=True, num_beams=3)\n",
    "    return (tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
    "\n",
    "\n",
    "generate_response(\"Hey! How are you?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_pickle('./datasets/test.pkl')\n",
    "\n",
    "reference_sentences = []\n",
    "generated_sentences = []\n",
    "for index, row in test_df.sample(100).iterrows():\n",
    "    input_text, label = row['conversation']['input_text'], row['conversation']['label']\n",
    "    generated_sentences.append(generate_response(input_text))\n",
    "    reference_sentences.append(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_sentences, generated_sentences\n",
    "\n",
    "df = pd.DataFrame({'reference_sentences': reference_sentences,\n",
    "                  'generated_sentences': generated_sentences})\n",
    "\n",
    "df.to_pickle('./files/ref_gen.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_gen = pd.read_pickle('./files/ref_gen.pkl')\n",
    "reference_sentences = list(ref_gen['reference_sentences'])\n",
    "generated_sentences = list(ref_gen['generated_sentences'])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#BERT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT score (F1): 0.82\n"
     ]
    }
   ],
   "source": [
    "from bert_score import score\n",
    "\n",
    "precision, recall, f1 = score(\n",
    "    generated_sentences, reference_sentences, lang='en', verbose=False)\n",
    "\n",
    "print(f\"BERT score (F1): {f1.mean().item():.2f}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#BLEU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.0027, 'precisions': [0.06534823731728288, 0.0026954177897574125, 0.0, 0.0], 'brevity_penalty': 1.0, 'length_ratio': 1.3375503162737206, 'translation_length': 2326, 'reference_length': 1739}\n",
      "Average BLEU: 0.01965501051750046\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "bleu = evaluate.load(\"bleu\", module_type=\"metric\")\n",
    "\n",
    "bleu1 = bleu.compute(predictions=generated_sentences,\n",
    "                        references=reference_sentences, max_order=1)\n",
    "bleu2 = bleu.compute(predictions=generated_sentences,\n",
    "                        references=reference_sentences, max_order=2)\n",
    "bleu3 = bleu.compute(predictions=generated_sentences,\n",
    "                        references=reference_sentences, max_order=3)\n",
    "bleu4 = bleu.compute(predictions=generated_sentences,\n",
    "                        references=reference_sentences, max_order=4)\n",
    "\n",
    "print(bleu4)\n",
    "print('Average BLEU:', (bleu1['bleu'] +\n",
    "      bleu2['bleu'] + bleu3['bleu'] + bleu4['bleu'])/4)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#ROUGE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.10471544194048145,\n",
       " 'rouge2': 0.010833652934120343,\n",
       " 'rougeL': 0.09262833948512203,\n",
       " 'rougeLsum': 0.09199357239128711}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import evaluate\n",
    "rouge = evaluate.load('rouge')\n",
    "rouge_score = rouge.compute(\n",
    "    predictions=generated_sentences, references=reference_sentences)\n",
    "rouge_score\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#BLEURT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No checkpoint specified, defaulting to BLEURT-tiny.\n",
      "INFO:tensorflow:Reading checkpoint C:\\Users\\Debolina\\AppData\\Roaming\\Python\\Python311\\site-packages\\bleurt\\test_checkpoint.\n",
      "INFO:tensorflow:Config file found, reading.\n",
      "INFO:tensorflow:Will load checkpoint dbleurt_tiny\n",
      "INFO:tensorflow:Loads full paths and checks that files exists.\n",
      "INFO:tensorflow:... name:dbleurt_tiny\n",
      "INFO:tensorflow:... vocab_file:vocab.txt\n",
      "INFO:tensorflow:... bert_config_file:bert_config.json\n",
      "INFO:tensorflow:... do_lower_case:True\n",
      "INFO:tensorflow:... max_seq_length:512\n",
      "INFO:tensorflow:Creating BLEURT scorer.\n",
      "INFO:tensorflow:Creating WordPiece tokenizer.\n",
      "INFO:tensorflow:WordPiece tokenizer instantiated.\n",
      "INFO:tensorflow:Creating Eager Mode predictor.\n",
      "INFO:tensorflow:Loading model.\n",
      "INFO:tensorflow:BLEURT initialized.\n",
      "-0.693769249652053\n"
     ]
    }
   ],
   "source": [
    "from bleurt import score\n",
    "\n",
    "scorer = score.BleurtScorer()\n",
    "scores = scorer.score(references=reference_sentences,\n",
    "                      candidates=generated_sentences)\n",
    "print(sum(scores)/len(scores))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
